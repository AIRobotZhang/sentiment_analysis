{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Building a Sentiment Predicting Model on a Social Media Corpus\n",
    "\n",
    "### Using the SemEval 2017 Task 4A: Positive/Negative/Neutral Classifier Corpus\n",
    "\n",
    "This model does not incorporate vector word embeddings or any smoothing. \n",
    "\n",
    "Helpful Resources:\n",
    "https://medium.com/@thoszymkowiak/how-to-implement-sentiment-analysis-using-word-embedding-and-convolutional-neural-networks-on-keras-163197aef623\n",
    "\n",
    "SemEval Tweet Download: \n",
    "https://github.com/seirasto/twitter_download\n",
    "\n",
    "Good Post I found that most of this code is built off of\n",
    "https://ahmedbesbes.com/sentiment-analysis-on-twitter-using-word2vec-and-keras.html\n",
    "\n",
    "Potential other corpus to use (1.6million tweets as positive/negative)\n",
    "https://drive.google.com/uc?id=0B04GJPshIjmPRnZManQwWEdTZjg&export=download\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting keras\n",
      "  Downloading Keras-2.0.9-py2.py3-none-any.whl (299kB)\n",
      "\u001b[K    100% |████████████████████████████████| 307kB 1.5MB/s ta 0:00:011\n",
      "\u001b[?25hRequirement already satisfied: numpy>=1.9.1 in /Users/dan/anaconda/lib/python3.5/site-packages (from keras)\n",
      "Requirement already satisfied: scipy>=0.14 in /Users/dan/anaconda/lib/python3.5/site-packages (from keras)\n",
      "Requirement already satisfied: pyyaml in /Users/dan/anaconda/lib/python3.5/site-packages (from keras)\n",
      "Requirement already satisfied: six>=1.9.0 in /Users/dan/anaconda/lib/python3.5/site-packages (from keras)\n",
      "Installing collected packages: keras\n",
      "Successfully installed keras-2.0.9\n"
     ]
    }
   ],
   "source": [
    "!pip install keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Standard python helper libraries.\n",
    "import collections\n",
    "import itertools\n",
    "import json\n",
    "import os\n",
    "import re\n",
    "import sys\n",
    "import time\n",
    "\n",
    "# Numerical manipulation libraries.\n",
    "import numpy\n",
    "import pandas as pd\n",
    "from scipy import stats\n",
    "import scipy.optimize\n",
    "\n",
    "# NLTK\n",
    "import nltk\n",
    "from nltk.tokenize import word_tokenize\n",
    "\n",
    "# Helper libraries (from w266 Materials).\n",
    "# import segment\n",
    "#from shared_lib import utils\n",
    "from shared_lib import vocabulary\n",
    "\n",
    "# Machine Learning Packages\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Word2Vec Model\n",
    "import gensim\n",
    "from gensim.models.word2vec import Word2Vec # the word2vec model gensim class\n",
    "\n",
    "# Keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import LSTM, Conv1D, Flatten, Dropout\n",
    "from keras.layers.embeddings import Embedding\n",
    "from keras.preprocessing import sequence\n",
    "from keras.callbacks import TensorBoard\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>628949369883000832</td>\n",
       "      <td>negative</td>\n",
       "      <td>dear @Microsoft the newOoffice for Mac is grea...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>628976607420645377</td>\n",
       "      <td>negative</td>\n",
       "      <td>@Microsoft how about you make a system that do...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>629023169169518592</td>\n",
       "      <td>negative</td>\n",
       "      <td>Not Available</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>629179223232479232</td>\n",
       "      <td>negative</td>\n",
       "      <td>Not Available</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>629186282179153920</td>\n",
       "      <td>neutral</td>\n",
       "      <td>If I make a game as a #windows10 Universal App...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>629226490152914944</td>\n",
       "      <td>positive</td>\n",
       "      <td>Microsoft, I may not prefer your gaming branch...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>629345637155360768</td>\n",
       "      <td>negative</td>\n",
       "      <td>@MikeWolf1980 @Microsoft I will be downgrading...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>629394528336637953</td>\n",
       "      <td>negative</td>\n",
       "      <td>@Microsoft 2nd computer with same error!!! #Wi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>629650766580609026</td>\n",
       "      <td>positive</td>\n",
       "      <td>Just ordered my 1st ever tablet; @Microsoft Su...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>629797991826722816</td>\n",
       "      <td>negative</td>\n",
       "      <td>After attempting a reinstall, it still bricks,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>630159517058142208</td>\n",
       "      <td>positive</td>\n",
       "      <td>Sunday morning, quiet day so time to welcome i...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>630542330827771904</td>\n",
       "      <td>negative</td>\n",
       "      <td>Did @Microsoft break Windows 10? Was working f...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>630636736746422272</td>\n",
       "      <td>negative</td>\n",
       "      <td>Not Available</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>630807124872970240</td>\n",
       "      <td>neutral</td>\n",
       "      <td>@spyderharrison @Microsoft the reason I ask is...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>630818265799921664</td>\n",
       "      <td>positive</td>\n",
       "      <td>Innovation for jobs is just around the corner ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>630909171437801472</td>\n",
       "      <td>neutral</td>\n",
       "      <td>OK this is my pure speculation.  @Microsoft ow...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>630982270409572352</td>\n",
       "      <td>neutral</td>\n",
       "      <td>We are still taking registrations for our Educ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>631104156187627520</td>\n",
       "      <td>negative</td>\n",
       "      <td>For the 1st time @Skype has a \"High Startup im...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>631223085476261890</td>\n",
       "      <td>negative</td>\n",
       "      <td>#teens @BillGates 1st company failed miserably...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>631368262979297281</td>\n",
       "      <td>positive</td>\n",
       "      <td>#Vote for @AIESEC to become the 10th Global no...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>631521079245307904</td>\n",
       "      <td>positive</td>\n",
       "      <td>Top 5 most searched for Back-to-School topics ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>631543121407442946</td>\n",
       "      <td>negative</td>\n",
       "      <td>@Microsoft support for 365 has been terrible. ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>631696872323850240</td>\n",
       "      <td>positive</td>\n",
       "      <td>@trucker_squigz @Microsoft @MISpeedway @nation...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>631792365590695936</td>\n",
       "      <td>negative</td>\n",
       "      <td>Not Available</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>631842974268305408</td>\n",
       "      <td>positive</td>\n",
       "      <td>@ScottArbeit @GabeAul @Microsoft isntall the n...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>631843393971204097</td>\n",
       "      <td>positive</td>\n",
       "      <td>@taehongmin1 We have an IOT workshop by @Micro...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>631936716522278912</td>\n",
       "      <td>neutral</td>\n",
       "      <td>@kenttaylor333 @YourAnonNews @Microsoft the op...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>632374683334258688</td>\n",
       "      <td>negative</td>\n",
       "      <td>Hey @Microsoft, I reserved my copy of @Windows...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>632536348419690496</td>\n",
       "      <td>negative</td>\n",
       "      <td>@eyesonfoxorg @Microsoft I'm still using Vista...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>632805868334153728</td>\n",
       "      <td>negative</td>\n",
       "      <td>@Microsoft Is it normal that it takes hours to...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5861</th>\n",
       "      <td>634021249283420161</td>\n",
       "      <td>positive</td>\n",
       "      <td>We'll run it back. But it's STH day here in Fl...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5862</th>\n",
       "      <td>634061328550883328</td>\n",
       "      <td>positive</td>\n",
       "      <td>Not Available</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5863</th>\n",
       "      <td>634184470338383873</td>\n",
       "      <td>positive</td>\n",
       "      <td>Not Available</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5864</th>\n",
       "      <td>634353168596340736</td>\n",
       "      <td>neutral</td>\n",
       "      <td>It's the Atlanta Falcons (1-0) against the New...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5865</th>\n",
       "      <td>634355631940612097</td>\n",
       "      <td>positive</td>\n",
       "      <td>Who's ready for some #GiantsFootball? The G-Me...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5866</th>\n",
       "      <td>634372935541592065</td>\n",
       "      <td>positive</td>\n",
       "      <td>I'll be live streaming the sad Giants fans via...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5867</th>\n",
       "      <td>634412669727047681</td>\n",
       "      <td>positive</td>\n",
       "      <td>I can't wait to see the Giants this Saturday a...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5868</th>\n",
       "      <td>634762357563129857</td>\n",
       "      <td>neutral</td>\n",
       "      <td>Not Available</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5869</th>\n",
       "      <td>634800750833594368</td>\n",
       "      <td>positive</td>\n",
       "      <td>I have one possibly two extra tickets to see Z...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5870</th>\n",
       "      <td>634902054562086912</td>\n",
       "      <td>neutral</td>\n",
       "      <td>im going to metlife tomorrow for a preseason g...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5871</th>\n",
       "      <td>635129647747989504</td>\n",
       "      <td>neutral</td>\n",
       "      <td>@RawbCas3 Alright, let me know. Want to see AC...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5872</th>\n",
       "      <td>635460536445063168</td>\n",
       "      <td>positive</td>\n",
       "      <td>Going to the Giants-Panthers game December 20 ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5873</th>\n",
       "      <td>635599514556956672</td>\n",
       "      <td>positive</td>\n",
       "      <td>Not Available</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5874</th>\n",
       "      <td>635658990123360258</td>\n",
       "      <td>positive</td>\n",
       "      <td>Not Available</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5875</th>\n",
       "      <td>636324904258904065</td>\n",
       "      <td>positive</td>\n",
       "      <td>Looks like I am going to see my phins at Gille...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5876</th>\n",
       "      <td>636714456546975744</td>\n",
       "      <td>positive</td>\n",
       "      <td>Oney Thursday and Friday, MetLife for Giants-J...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5877</th>\n",
       "      <td>637340624031604736</td>\n",
       "      <td>negative</td>\n",
       "      <td>Not Available</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5878</th>\n",
       "      <td>637342059519680513</td>\n",
       "      <td>negative</td>\n",
       "      <td>Still bitter that they didn't tweet about MetL...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5879</th>\n",
       "      <td>637691185100947456</td>\n",
       "      <td>positive</td>\n",
       "      <td>Not Available</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5880</th>\n",
       "      <td>637874723288936448</td>\n",
       "      <td>positive</td>\n",
       "      <td>Not Available</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5881</th>\n",
       "      <td>638382158420307968</td>\n",
       "      <td>neutral</td>\n",
       "      <td>Not Available</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5882</th>\n",
       "      <td>638533993344864256</td>\n",
       "      <td>positive</td>\n",
       "      <td>Schreier Financial Services in Orange City wil...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5883</th>\n",
       "      <td>639166904813223937</td>\n",
       "      <td>positive</td>\n",
       "      <td>Heading up to MetLife tomorrow for the Jets game</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5884</th>\n",
       "      <td>639295526995890177</td>\n",
       "      <td>positive</td>\n",
       "      <td>Not Available</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5885</th>\n",
       "      <td>639804828739346432</td>\n",
       "      <td>positive</td>\n",
       "      <td>It's the first Football Friday of the year. Th...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5886</th>\n",
       "      <td>639855845958885376</td>\n",
       "      <td>positive</td>\n",
       "      <td>@Racalto_SK ok good to know. Punting at MetLif...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5887</th>\n",
       "      <td>639979760735662080</td>\n",
       "      <td>neutral</td>\n",
       "      <td>everyone who sat around me at metlife was so a...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5888</th>\n",
       "      <td>640196838260363269</td>\n",
       "      <td>neutral</td>\n",
       "      <td>what giants or niners fans would wanna go to t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5889</th>\n",
       "      <td>640975710354567168</td>\n",
       "      <td>positive</td>\n",
       "      <td>Anybody want a ticket for tomorrow Colombia vs...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5890</th>\n",
       "      <td>641034340068143104</td>\n",
       "      <td>neutral</td>\n",
       "      <td>Mendez told me he'd drive me to MetLife on Sun...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5891 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                       0         1  \\\n",
       "0     628949369883000832  negative   \n",
       "1     628976607420645377  negative   \n",
       "2     629023169169518592  negative   \n",
       "3     629179223232479232  negative   \n",
       "4     629186282179153920   neutral   \n",
       "5     629226490152914944  positive   \n",
       "6     629345637155360768  negative   \n",
       "7     629394528336637953  negative   \n",
       "8     629650766580609026  positive   \n",
       "9     629797991826722816  negative   \n",
       "10    630159517058142208  positive   \n",
       "11    630542330827771904  negative   \n",
       "12    630636736746422272  negative   \n",
       "13    630807124872970240   neutral   \n",
       "14    630818265799921664  positive   \n",
       "15    630909171437801472   neutral   \n",
       "16    630982270409572352   neutral   \n",
       "17    631104156187627520  negative   \n",
       "18    631223085476261890  negative   \n",
       "19    631368262979297281  positive   \n",
       "20    631521079245307904  positive   \n",
       "21    631543121407442946  negative   \n",
       "22    631696872323850240  positive   \n",
       "23    631792365590695936  negative   \n",
       "24    631842974268305408  positive   \n",
       "25    631843393971204097  positive   \n",
       "26    631936716522278912   neutral   \n",
       "27    632374683334258688  negative   \n",
       "28    632536348419690496  negative   \n",
       "29    632805868334153728  negative   \n",
       "...                  ...       ...   \n",
       "5861  634021249283420161  positive   \n",
       "5862  634061328550883328  positive   \n",
       "5863  634184470338383873  positive   \n",
       "5864  634353168596340736   neutral   \n",
       "5865  634355631940612097  positive   \n",
       "5866  634372935541592065  positive   \n",
       "5867  634412669727047681  positive   \n",
       "5868  634762357563129857   neutral   \n",
       "5869  634800750833594368  positive   \n",
       "5870  634902054562086912   neutral   \n",
       "5871  635129647747989504   neutral   \n",
       "5872  635460536445063168  positive   \n",
       "5873  635599514556956672  positive   \n",
       "5874  635658990123360258  positive   \n",
       "5875  636324904258904065  positive   \n",
       "5876  636714456546975744  positive   \n",
       "5877  637340624031604736  negative   \n",
       "5878  637342059519680513  negative   \n",
       "5879  637691185100947456  positive   \n",
       "5880  637874723288936448  positive   \n",
       "5881  638382158420307968   neutral   \n",
       "5882  638533993344864256  positive   \n",
       "5883  639166904813223937  positive   \n",
       "5884  639295526995890177  positive   \n",
       "5885  639804828739346432  positive   \n",
       "5886  639855845958885376  positive   \n",
       "5887  639979760735662080   neutral   \n",
       "5888  640196838260363269   neutral   \n",
       "5889  640975710354567168  positive   \n",
       "5890  641034340068143104   neutral   \n",
       "\n",
       "                                                      2  \n",
       "0     dear @Microsoft the newOoffice for Mac is grea...  \n",
       "1     @Microsoft how about you make a system that do...  \n",
       "2                                         Not Available  \n",
       "3                                         Not Available  \n",
       "4     If I make a game as a #windows10 Universal App...  \n",
       "5     Microsoft, I may not prefer your gaming branch...  \n",
       "6     @MikeWolf1980 @Microsoft I will be downgrading...  \n",
       "7     @Microsoft 2nd computer with same error!!! #Wi...  \n",
       "8     Just ordered my 1st ever tablet; @Microsoft Su...  \n",
       "9     After attempting a reinstall, it still bricks,...  \n",
       "10    Sunday morning, quiet day so time to welcome i...  \n",
       "11    Did @Microsoft break Windows 10? Was working f...  \n",
       "12                                        Not Available  \n",
       "13    @spyderharrison @Microsoft the reason I ask is...  \n",
       "14    Innovation for jobs is just around the corner ...  \n",
       "15    OK this is my pure speculation.  @Microsoft ow...  \n",
       "16    We are still taking registrations for our Educ...  \n",
       "17    For the 1st time @Skype has a \"High Startup im...  \n",
       "18    #teens @BillGates 1st company failed miserably...  \n",
       "19    #Vote for @AIESEC to become the 10th Global no...  \n",
       "20    Top 5 most searched for Back-to-School topics ...  \n",
       "21    @Microsoft support for 365 has been terrible. ...  \n",
       "22    @trucker_squigz @Microsoft @MISpeedway @nation...  \n",
       "23                                        Not Available  \n",
       "24    @ScottArbeit @GabeAul @Microsoft isntall the n...  \n",
       "25    @taehongmin1 We have an IOT workshop by @Micro...  \n",
       "26    @kenttaylor333 @YourAnonNews @Microsoft the op...  \n",
       "27    Hey @Microsoft, I reserved my copy of @Windows...  \n",
       "28    @eyesonfoxorg @Microsoft I'm still using Vista...  \n",
       "29    @Microsoft Is it normal that it takes hours to...  \n",
       "...                                                 ...  \n",
       "5861  We'll run it back. But it's STH day here in Fl...  \n",
       "5862                                      Not Available  \n",
       "5863                                      Not Available  \n",
       "5864  It's the Atlanta Falcons (1-0) against the New...  \n",
       "5865  Who's ready for some #GiantsFootball? The G-Me...  \n",
       "5866  I'll be live streaming the sad Giants fans via...  \n",
       "5867  I can't wait to see the Giants this Saturday a...  \n",
       "5868                                      Not Available  \n",
       "5869  I have one possibly two extra tickets to see Z...  \n",
       "5870  im going to metlife tomorrow for a preseason g...  \n",
       "5871  @RawbCas3 Alright, let me know. Want to see AC...  \n",
       "5872  Going to the Giants-Panthers game December 20 ...  \n",
       "5873                                      Not Available  \n",
       "5874                                      Not Available  \n",
       "5875  Looks like I am going to see my phins at Gille...  \n",
       "5876  Oney Thursday and Friday, MetLife for Giants-J...  \n",
       "5877                                      Not Available  \n",
       "5878  Still bitter that they didn't tweet about MetL...  \n",
       "5879                                      Not Available  \n",
       "5880                                      Not Available  \n",
       "5881                                      Not Available  \n",
       "5882  Schreier Financial Services in Orange City wil...  \n",
       "5883   Heading up to MetLife tomorrow for the Jets game  \n",
       "5884                                      Not Available  \n",
       "5885  It's the first Football Friday of the year. Th...  \n",
       "5886  @Racalto_SK ok good to know. Punting at MetLif...  \n",
       "5887  everyone who sat around me at metlife was so a...  \n",
       "5888  what giants or niners fans would wanna go to t...  \n",
       "5889  Anybody want a ticket for tomorrow Colombia vs...  \n",
       "5890  Mendez told me he'd drive me to MetLife on Sun...  \n",
       "\n",
       "[5891 rows x 3 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Pull in Tweet Data (Must be downloaded using https://github.com/seirasto/twitter_download)\n",
    "tweets = pd.read_table(\"Data/twitter_download-master/2016train.txt_semeval_tweets.txt\", header=None)\n",
    "tweets\n",
    "\n",
    "# SemEval Dataset is actually relatively small (6000 tweets in 2016). \n",
    "# We can group all of the Train/Test/Dev data from 2013 through 2016 to get more.\n",
    "# Additionally, we could consider using this data which has 1.6 million rows but it is only a binary positive/negative class \n",
    "# https://drive.google.com/uc?id=0B04GJPshIjmPRnZManQwWEdTZjg&export=download"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Segregate X and Y\n",
    "#X = tweets[2]\n",
    "Y = tweets[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'X' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-5-018ea513c961>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Tokenize each Tweet (really slow, need to optimize for larger corpora?)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtweet\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m     \u001b[0mX\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtweet\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'X' is not defined"
     ]
    }
   ],
   "source": [
    "# Tokenize each Tweet (really slow, need to optimize for larger corpora?)\n",
    "for i, tweet in enumerate(X):\n",
    "    X[i,] = tweet.split()\n",
    "\n",
    "\n",
    "# print(X)\n",
    "\n",
    "# Alternatively, use this?\n",
    "# from nltk.tokenize import TweetTokenizer # a tweet tokenizer from nltk.\n",
    "# tokenizer = TweetTokenizer()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Good idea on using the tokenizer.  we can use this as a function with df.apply to speed this up! Check out the stack overflow solution below for some inspiration.  Some exploratory code is below\n",
    "\n",
    "https://stackoverflow.com/questions/33098040/how-to-use-word-tokenize-in-data-frame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0    dear @Microsoft the newOoffice for Mac is grea...\n",
      "1    @Microsoft how about you make a system that do...\n",
      "Name: 2, dtype: object\n"
     ]
    }
   ],
   "source": [
    "#rewriting as a new dataframe to avoid overlap with your tokenized solution\n",
    "df = pd.read_table(\"Data/twitter_download-master/2016train.txt_semeval_tweets.txt\", header=None)\n",
    "print (df[2].head(2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['dear', '@Microsoft', 'the', 'newOoffice', 'for', 'Mac', 'is', 'great', 'and', 'all', ',', 'but', 'no', 'Lync', 'update', '?', \"C'mon\", '.']\n"
     ]
    }
   ],
   "source": [
    "from nltk.tokenize import TweetTokenizer # a tweet tokenizer from nltk.\n",
    "t = TweetTokenizer()\n",
    "print (t.tokenize(df[2][0])) #proof that tokenize method works"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "df.apply 0.334456205368042\n"
     ]
    }
   ],
   "source": [
    "#proof in the pudding - let's time it\n",
    "start = time.time() \n",
    "df['unigrams'] = df[2].apply(t.tokenize)\n",
    "print ('df.apply', (time.time() - start))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['dear', '@Microsoft', 'the', 'newOoffice', 'for', 'Mac', 'is', 'great', 'and', 'all', ',', 'but', 'no', 'Lync', 'update', '?', \"C'mon\", '.']\n"
     ]
    }
   ],
   "source": [
    "#print (X[0]) \n",
    "print (df.unigrams[0]) # TweetTokenizer is better (see comma)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>unigrams</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>628949369883000832</td>\n",
       "      <td>negative</td>\n",
       "      <td>dear @Microsoft the newOoffice for Mac is grea...</td>\n",
       "      <td>[dear, @Microsoft, the, newOoffice, for, Mac, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>628976607420645377</td>\n",
       "      <td>negative</td>\n",
       "      <td>@Microsoft how about you make a system that do...</td>\n",
       "      <td>[@Microsoft, how, about, you, make, a, system,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>629023169169518592</td>\n",
       "      <td>negative</td>\n",
       "      <td>Not Available</td>\n",
       "      <td>[Not, Available]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>629179223232479232</td>\n",
       "      <td>negative</td>\n",
       "      <td>Not Available</td>\n",
       "      <td>[Not, Available]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>629186282179153920</td>\n",
       "      <td>neutral</td>\n",
       "      <td>If I make a game as a #windows10 Universal App...</td>\n",
       "      <td>[If, I, make, a, game, as, a, #windows10, Univ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    0         1  \\\n",
       "0  628949369883000832  negative   \n",
       "1  628976607420645377  negative   \n",
       "2  629023169169518592  negative   \n",
       "3  629179223232479232  negative   \n",
       "4  629186282179153920   neutral   \n",
       "\n",
       "                                                   2  \\\n",
       "0  dear @Microsoft the newOoffice for Mac is grea...   \n",
       "1  @Microsoft how about you make a system that do...   \n",
       "2                                      Not Available   \n",
       "3                                      Not Available   \n",
       "4  If I make a game as a #windows10 Universal App...   \n",
       "\n",
       "                                            unigrams  \n",
       "0  [dear, @Microsoft, the, newOoffice, for, Mac, ...  \n",
       "1  [@Microsoft, how, about, you, make, a, system,...  \n",
       "2                                   [Not, Available]  \n",
       "3                                   [Not, Available]  \n",
       "4  [If, I, make, a, game, as, a, #windows10, Univ...  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Based on above, I'm going to replace X with df.unigrams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X = df.unigrams"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preprocessing & (future) Feature Engineering"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Split Train and Test Sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4395    [#Apology, to, Jeb, Bush, for, John, Dempsey, ...\n",
      "4068    [Top, 5, Gambling, Apps, for, the, iPad, http:...\n",
      "3710                                     [Not, Available]\n",
      "4516    [@Milbank, doesn't, think, Vice, President, Jo...\n",
      "4243    [1st, day, back, at, work, after, a, terrible,...\n",
      "4288                                     [Not, Available]\n",
      "4916                                     [Not, Available]\n",
      "1360    [1, ), may, be, wrong, ,, but, if, I, read, it...\n",
      "1012    [@GailSimone, Donald, Trump, may, think, he's,...\n",
      "1538    [#nowplaying, Bob, Marley, -, Sun, Is, Shining...\n",
      "Name: unigrams, dtype: object\n"
     ]
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X,Y,test_size=0.20,random_state=100)\n",
    "print(X_train[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4395    [#Apology, to, Jeb, Bush, for, John, Dempsey, ...\n",
      "4068    [Top, 5, Gambling, Apps, for, the, iPad, http:...\n",
      "3710                                     [Not, Available]\n",
      "4516    [@Milbank, doesn't, think, Vice, President, Jo...\n",
      "4243    [1st, day, back, at, work, after, a, terrible,...\n",
      "4288                                     [Not, Available]\n",
      "4916                                     [Not, Available]\n",
      "1360    [1, ), may, be, wrong, ,, but, if, I, read, it...\n",
      "1012    [@GailSimone, Donald, Trump, may, think, he's,...\n",
      "1538    [#nowplaying, Bob, Marley, -, Sun, Is, Shining...\n",
      "Name: unigrams, dtype: object\n"
     ]
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X,Y,test_size=0.20,random_state=100)\n",
    "print(X_train[:10])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Word2Vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "57893"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Convert each word into a vector representation. Couldn't get Keras working with straight indexes for each word so I followed the steps laid out here:\n",
    "# https://ahmedbesbes.com/sentiment-analysis-on-twitter-using-word2vec-and-keras.html\n",
    "\n",
    "vec_dim = 10\n",
    "\n",
    "tweet_w2v = Word2Vec(size=vec_dim, min_count=2) #vector size and minimum threshold to include for rare words\n",
    "tweet_w2v.build_vocab(x for x in X_train)\n",
    "tweet_w2v.train((x for x in X_train), total_examples=tweet_w2v.corpus_count, epochs=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('profile', 0.92231285572052),\n",
       " ('note', 0.8966584205627441),\n",
       " ('DONT', 0.8914517164230347),\n",
       " ('companies', 0.8803945779800415),\n",
       " ('loud', 0.868857741355896),\n",
       " ('Work', 0.8656846284866333),\n",
       " ('simple', 0.8618882298469543),\n",
       " ('include', 0.8560652136802673),\n",
       " ('British', 0.8373156785964966),\n",
       " ('Committee', 0.8337675333023071)]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tweet_w2v.most_similar('yes')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create Word Vectors \n",
    "https://ahmedbesbes.com/sentiment-analysis-on-twitter-using-word2vec-and-keras.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "building tf-idf matrix ...\n",
      "vocab size : 918\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "print('building tf-idf matrix ...')\n",
    "vectorizer = TfidfVectorizer(analyzer=lambda x: x, min_df=10)\n",
    "matrix = vectorizer.fit_transform([x for x in X_train])\n",
    "tfidf = dict(zip(vectorizer.get_feature_names(), vectorizer.idf_))\n",
    "print('vocab size :', len(tfidf))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def buildWordVector(tokens, size):\n",
    "    vec = numpy.zeros(size).reshape((1, size))\n",
    "    count = 0.\n",
    "    for word in tokens:\n",
    "        try:\n",
    "            vec += tweet_w2v[word].reshape((1, size)) * tfidf[word]\n",
    "            count += 1.\n",
    "        except KeyError: # handling the case where the token is not\n",
    "                         # in the corpus. useful for testing.\n",
    "            continue\n",
    "    if count != 0:\n",
    "        vec /= count\n",
    "    return vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "train_vecs_w2v = numpy.concatenate([buildWordVector(z, vec_dim) for z in map(lambda x: x, X_train)])\n",
    "\n",
    "scaler = StandardScaler()\n",
    "scaler.fit(train_vecs_w2v)\n",
    "train_vecs_w2v = scaler.transform(train_vecs_w2v)\n",
    "\n",
    "test_vecs_w2v = numpy.concatenate([buildWordVector(z, vec_dim) for z in map(lambda x: x, X_test)])\n",
    "test_vecs_w2v = scaler.transform(test_vecs_w2v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original Y: 4395     neutral\n",
      "4068     neutral\n",
      "3710    positive\n",
      "4516     neutral\n",
      "4243    negative\n",
      "4288     neutral\n",
      "4916     neutral\n",
      "1360     neutral\n",
      "1012     neutral\n",
      "1538    positive\n",
      "Name: 1, dtype: object\n",
      "Encoded Y: [1 1 2 1 0 1 1 1 1 2]\n",
      "One Hot Y: [[ 0.  1.  0.]\n",
      " [ 0.  1.  0.]\n",
      " [ 0.  0.  1.]\n",
      " [ 0.  1.  0.]\n",
      " [ 1.  0.  0.]\n",
      " [ 0.  1.  0.]\n",
      " [ 0.  1.  0.]\n",
      " [ 0.  1.  0.]\n",
      " [ 0.  1.  0.]\n",
      " [ 0.  0.  1.]]\n"
     ]
    }
   ],
   "source": [
    "from keras.utils.np_utils import to_categorical\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "print(\"Original Y:\", y_train[:10])\n",
    "encoder = LabelEncoder()\n",
    "encoder.fit(Y)\n",
    "y_train = encoder.transform(y_train)\n",
    "y_test= encoder.transform(y_test)\n",
    "print(\"Encoded Y:\", y_train[:10])\n",
    "\n",
    "y_train = to_categorical(y_train, 3)\n",
    "y_test = to_categorical(y_test, 3)\n",
    "print(\"One Hot Y:\", y_train[:10])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CNN Model (really simple)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/9\n",
      " - 0s - loss: 1.0253 - acc: 0.4962\n",
      "Epoch 2/9\n",
      " - 0s - loss: 0.9917 - acc: 0.5155\n",
      "Epoch 3/9\n",
      " - 0s - loss: 0.9893 - acc: 0.5155\n",
      "Epoch 4/9\n",
      " - 0s - loss: 0.9880 - acc: 0.5149\n",
      "Epoch 5/9\n",
      " - 0s - loss: 0.9872 - acc: 0.5146\n",
      "Epoch 6/9\n",
      " - 0s - loss: 0.9861 - acc: 0.5146\n",
      "Epoch 7/9\n",
      " - 0s - loss: 0.9843 - acc: 0.5129\n",
      "Epoch 8/9\n",
      " - 0s - loss: 0.9849 - acc: 0.5178\n",
      "Epoch 9/9\n",
      " - 0s - loss: 0.9847 - acc: 0.5151\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x11a8c4438>"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Pad the sequence to the same length\n",
    "# train_vecs_w2v = sequence.pad_sequences(train_vecs_w2v, maxlen=vec_dim)\n",
    "# test_vecs_w2v = sequence.pad_sequences(test_vecs_w2v, maxlen=vec_dim)\n",
    "\n",
    "# Build Keras Model\n",
    "model = Sequential()\n",
    "model.add(Dense(32, activation='relu', input_dim=vec_dim))\n",
    "model.add(Dense(3, activation='softmax'))\n",
    "model.compile(optimizer='rmsprop',\n",
    "              loss='categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "model.fit(train_vecs_w2v, y_train, epochs=9, batch_size=32, verbose=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 50.72%\n"
     ]
    }
   ],
   "source": [
    "score = model.evaluate(test_vecs_w2v, y_test, batch_size=128, verbose=2)\n",
    "print(\"Accuracy: %.2f%%\" % (score[1]*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# # LSTM for sequence classification\n",
    "\n",
    "# from keras.models import Sequential\n",
    "# from keras.layers import Dense\n",
    "# from keras.layers import LSTM, Conv1D, Flatten, Dropout\n",
    "# from keras.layers.embeddings import Embedding\n",
    "# from keras.preprocessing import sequence\n",
    "# from keras.callbacks import TensorBoard\n",
    "\n",
    "# # # Using keras to load the dataset with the top_words\n",
    "# # top_words = 10000\n",
    "\n",
    "\n",
    "# # # Pad the sequence to the same length\n",
    "# max_review_length = vec_dim\n",
    "# X_train = sequence.pad_sequences(train_vecs_w2v, maxlen=max_review_length)\n",
    "# X_test = sequence.pad_sequences(test_vecs_w2v, maxlen=max_review_length)\n",
    "\n",
    "# # Using embedding from Keras\n",
    "# # embedding_vecor_length = 300\n",
    "# model = Sequential()\n",
    "# # model.add(Embedding(top_words, embedding_vecor_length, input_length=max_review_length))\n",
    "\n",
    "\n",
    "# # Convolutional model (3x conv, flatten, 2x dense)\n",
    "# model.add(Conv1D(64, 3, padding='same', input_shape=(None, vec_dim)))\n",
    "# model.add(Conv1D(32, 3, padding='same'))\n",
    "# model.add(Conv1D(16, 3, padding='same'))\n",
    "# model.add(Flatten())\n",
    "# model.add(Dropout(0.2))\n",
    "# model.add(Dense(180,activation='relu'))\n",
    "# model.add(Dropout(0.2))\n",
    "# model.add(Dense(1,activation='softmax'))\n",
    "\n",
    "# # Log to tensorboard\n",
    "# tensorBoardCallback = TensorBoard(log_dir='./logs', write_graph=True)\n",
    "# model.compile(loss='categorical_crossentropy', optimizer='adagrad', metrics=['accuracy'])\n",
    "\n",
    "# model.fit(train_vecs_w2v, y_train, nb_epoch=3, callbacks=[tensorBoardCallback], batch_size=64)\n",
    "\n",
    "# # Evaluation on the test set\n",
    "# scores = model.evaluate(test_vecs_w2v, y_test, verbose=0)\n",
    "# print(\"Accuracy: %.2f%%\" % (scores[1]*100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Applied to Reddit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Function to Predict Positive/Neutral/Negative\n",
    "\n",
    "def prediction(text):\n",
    "    sentiment = [\"Negative\", \"Neutral\", \"Positive\"]\n",
    "    text = text.split() # Tokenize\n",
    "    text = buildWordVector(text, vec_dim)\n",
    "    text = scaler.transform(text)\n",
    "    predic = model.predict(text, batch_size=32)\n",
    "    result = sentiment[predic.argmax(axis=1)[0]]\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: More than 400 millionaires tell Congress: Don’t cut our taxes, ups: 9758, downs: 0, Have we visited: False\n",
      "--------------------\n",
      "Parent ID: 7ck1f6\n",
      "Comment ID: dpqhmjh\n",
      "\n",
      "As a reminder, this subreddit [is for civil discussion.](/r/politics/wiki/index#wiki_be_civil)\n",
      "\n",
      "In general, be courteous to others. Attack ideas, not users. Personal insults, shill or troll accusations, hate speech, and other incivility violations can result in a permanent ban. \n",
      "\n",
      "If you see comments in violation of our rules, please report them.\n",
      "\n",
      "***\n",
      "\n",
      "\n",
      "*I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/politics) if you have any questions or concerns.*\n",
      "########## PREDICTED SENTIMENT: Positive ##########\n",
      "--------------------\n",
      "Parent ID: 7ck1f6\n",
      "Comment ID: dpqhqap\n",
      "But four **billionaires** (who keep the GOP in power) say: Do.\n",
      "########## PREDICTED SENTIMENT: Positive ##########\n",
      "--------------------\n",
      "Parent ID: 7ck1f6\n",
      "Comment ID: dpqhor8\n",
      "And as you know, four hundred millionaires have more say than four hundred million of us peasants.  Pathetic.\n",
      "########## PREDICTED SENTIMENT: Positive ##########\n",
      "--------------------\n",
      "Parent ID: 7ck1f6\n",
      "Comment ID: dpqhuk8\n",
      "High income people (or anyone) are not charged a dime for reinvesting their income in business, this IS the way to create jobs, and heavily taxing (it was 90%+) those who choose not not to reinvest their top 5% income was how America was brought out of the great depression.\n",
      "########## PREDICTED SENTIMENT: Positive ##########\n",
      "--------------------\n",
      "Parent ID: 7ck1f6\n",
      "Comment ID: dpqinyr\n",
      "Combined donations to congress for those Americans: a couple million.\n",
      "\n",
      "Same for the top 0.01%: a lot more.\n",
      "\n",
      "Get money out of politics. It is poisoning our democracy. \n",
      "########## PREDICTED SENTIMENT: Positive ##########\n",
      "--------------------\n",
      "Parent ID: 7ck1f6\n",
      "Comment ID: dpqmu0a\n",
      "Did you know that there are over 10 million millionaires in the US? .00004% of millionaires said something. Hooray.\n",
      "########## PREDICTED SENTIMENT: Positive ##########\n",
      "--------------------\n",
      "Parent ID: 7ck1f6\n",
      "Comment ID: dpqij2o\n",
      "Reminds me of this gem of an op-ed from 2012 by Stephen King: [Tax Me, for F@%&’s Sake!](https://www.thedailybeast.com/stephen-king-tax-me-for-fands-sake)\n",
      "########## PREDICTED SENTIMENT: Positive ##########\n",
      "--------------------\n",
      "Parent ID: 7ck1f6\n",
      "Comment ID: dpqhr22\n",
      "Any chance someone will copy and paste the article? Thank you. \n",
      "########## PREDICTED SENTIMENT: Positive ##########\n",
      "--------------------\n",
      "Parent ID: 7ck1f6\n",
      "Comment ID: dpqjxcd\n",
      "This is trump with a solution looking for a problem.  When Reagan did it, the top tax rate was 70%.  Trump is stuck in a different era...\n",
      "\n",
      "\n",
      "########## PREDICTED SENTIMENT: Positive ##########\n",
      "--------------------\n",
      "Parent ID: 7ck1f6\n",
      "Comment ID: dpqqhfu\n",
      "I'll sign it to. Pretty safe since I'm not a millionaire so I'm already not getting a tax cut.\n",
      "########## PREDICTED SENTIMENT: Positive ##########\n",
      "--------------------\n",
      "Parent ID: 7ck1f6\n",
      "Comment ID: dpqhsa0\n",
      "Sadly they won't listen. A certain few (Ryan, McConnell etc) are devotes of a certain way of thinking, a cult and they will destroy the country to appease those they serve. The GOP is evil and doing the work of Satan.\n",
      "########## PREDICTED SENTIMENT: Positive ##########\n",
      "--------------------\n",
      "Parent ID: 7ck1f6\n",
      "Comment ID: dpqthoo\n",
      "Politicians to these millionaires \"But your not the ones who pay us\"\n",
      "########## PREDICTED SENTIMENT: Positive ##########\n",
      "--------------------\n",
      "Parent ID: 7ck1f6\n",
      "Comment ID: dpqrk19\n",
      "Millionaires? Wow, you own a house in the city.\n",
      "########## PREDICTED SENTIMENT: Positive ##########\n",
      "--------------------\n",
      "Parent ID: 7ck1f6\n",
      "Comment ID: dpqp2vo\n",
      "Yeah, just how all the top ISPs are telling the FCC that they support net neutrality while they lobby in the contrary.\n",
      "########## PREDICTED SENTIMENT: Positive ##########\n",
      "--------------------\n",
      "Parent ID: 7ck1f6\n",
      "Comment ID: dpqszsk\n",
      "That's an insignificant number. \n",
      "########## PREDICTED SENTIMENT: Neutral ##########\n",
      "--------------------\n",
      "Parent ID: 7ck1f6\n",
      "Comment ID: dpqrkaf\n",
      "400 millionaires isn't saying a whole lot, tbh.  A lot of people who manage their money well throughout their lives can become millionaires.  My friend's mother is an accountant, and one of her clients retired with a net worth of over $1,000,000 as a teacher.  \n",
      "########## PREDICTED SENTIMENT: Positive ##########\n",
      "--------------------\n",
      "Parent ID: 7ck1f6\n",
      "Comment ID: dpqtfun\n",
      "400? And just how many millionaire actually do want taxes cut?\n",
      "########## PREDICTED SENTIMENT: Neutral ##########\n",
      "--------------------\n",
      "Parent ID: 7ck1f6\n",
      "Comment ID: dpqvkgb\n",
      ">“I have a big income. If my income gets bigger, I’m not going to invest more. I'll just save more,” said Crandall, who is retired.\n",
      "\n",
      "This should be the end of any discussion regarding the \"tax cuts create jobs\" bullshit, or the \"trickle-down\" voodoo they still want to believe actually works. Rich people are rich because _they already have lots of money_. That's what being rich is. Why would any economic strategy be focused on making rich people richer?\n",
      "\n",
      "Money is useless unless it's spent, and rich people don't spend as much as they should compared to how much _more_ money than others they already have. Look at spending as a percentage of income and savings. You know who spends _a lot_ in this economy? Poor, lower and middle class people. They spend almost 100% of their income, and their savings, if they have any at all, are relatively short-term that will become spending on things like cars, homes or vacations soon. _Those_ are the investments that create jobs. Anytime someone goes grocery shopping, it creates incentive for jobs. People who can finally afford a new car create incentive for jobs in the auto-factories.\n",
      "\n",
      "Give a billionaire more money, and what does he do with it? Will he get excited and go on a spending spree? No, of course not, it'll go right back in his massive savings account or investment fund, none of which will create _any_ incentive for more jobs anywhere.\n",
      "\n",
      "Even companies don't base their growth on simply how much money is in the bank. They base it on how big the _market_ is to expand in. If people, those who _are_ the market, can't afford to buy any more things or services, there's no market to expand in, and thus no more jobs to create. Giving corporations more cash _does not_ create jobs. It just increases their profit margins and enriches its owners, which are already the people getting the biggest tax cuts, and who are the ones who _don't_ invest their savings back into the economy.\n",
      "\n",
      "Holy shit, this is such a simple fucking thing to understand. You don't even have to be an economist. The fact that congress refuses to understand it just makes it painfully obvious how bought and corrupted they are, and whose errands they're running pushing these stupid tax plans.\n",
      "########## PREDICTED SENTIMENT: Positive ##########\n",
      "--------------------\n",
      "Parent ID: 7ck1f6\n",
      "Comment ID: dpqvpc9\n",
      "All I'm hearing is they really don't want Trumps tax plan. \n",
      "########## PREDICTED SENTIMENT: Positive ##########\n",
      "--------------------\n",
      "Parent ID: 7ck1f6\n",
      "Comment ID: dpqvwil\n",
      "Seeing as there are 11 MILLION millionaires in America, this does not seem like a representative endorsement. \n",
      "\n",
      "https://www.cnbc.com/2017/03/24/a-record-number-of-americans-are-now-millionaires-new-study-shows.html\n",
      "\n",
      "If you want to increase the standard of living increase the capacity of those to create wealth and growth.\n",
      "########## PREDICTED SENTIMENT: Positive ##########\n",
      "--------------------\n",
      "Parent ID: 7ck1f6\n",
      "Comment ID: dpqw989\n",
      "does millionaire mean anything anymore? \n",
      "\n",
      "In australia if you own a house then you are a millionaire. not a fancy house, any house. \n",
      "########## PREDICTED SENTIMENT: Positive ##########\n",
      "--------------------\n",
      "Parent ID: 7ck1f6\n",
      "Comment ID: dpqwhk7\n",
      "I'm sure the real answer here is that these 400 to 500 millionaires have most of their Investments placed in areas that the new tax plan doesn't benefit, so they see this as an opportunity to look like the good guys to all us peasant folk.\n",
      "\n",
      "There are thousands of millionaires, tens of thousands probably. 400 really isn't a lot, and if they're Investments were going to benefit from this like the other \"smarter\" millionaires with their \"smarter\" Investments, they wouldn't be singing the same tune. This is a PR point grab for these people\n",
      "########## PREDICTED SENTIMENT: Positive ##########\n",
      "--------------------\n",
      "Parent ID: 7ck1f6\n",
      "Comment ID: dpqwiok\n",
      "how many of these millionaires are using tax havens to avoid paying the taxes they are supposed to?\n",
      "########## PREDICTED SENTIMENT: Positive ##########\n",
      "--------------------\n",
      "Parent ID: 7ck1f6\n",
      "Comment ID: dpqiepy\n",
      "Unfortunately, there’s got to be at least a couple of million millionaires in this country. Having 400 of them make this statement is not really significant in the slightest.\n",
      "########## PREDICTED SENTIMENT: Positive ##########\n",
      "--------------------\n",
      "Parent ID: 7ck1f6\n",
      "Comment ID: dpqt2ci\n",
      "There are 4.4million millionaires living in the US so this sample represents 0.009% of that population. It is my understanding that wealthy individuals in California and NY would be paying more under this tax plan. It is also my understanding that closing the carried interest loophole (If Trump gets his way) is still being considered but would require this tax plan to pass.\n",
      "\n",
      "\n",
      "Washington Post is owned by billionaire Jeff Bezos, not sure he's the best source for tax information.\n",
      "########## PREDICTED SENTIMENT: Positive ##########\n",
      "--------------------\n",
      "Parent ID: 7ck1f6\n",
      "Comment ID: dpqqzny\n",
      "400 millionaires is basically nothing... do people not realize how many millionaires are in the US? \n",
      "########## PREDICTED SENTIMENT: Positive ##########\n",
      "--------------------\n",
      "Parent ID: 7ck1f6\n",
      "Comment ID: dpqj0rz\n",
      "I'm sure they'll get right on that.\n",
      "########## PREDICTED SENTIMENT: Positive ##########\n",
      "--------------------\n",
      "Parent ID: 7ck1f6\n",
      "Comment ID: dpqry6t\n",
      "The cut is for all Americans? Who are 400 people to say otherwise.\n",
      "########## PREDICTED SENTIMENT: Positive ##########\n",
      "--------------------\n",
      "Parent ID: 7ck1f6\n",
      "Comment ID: dpqi3er\n",
      "To be fair, that's the same as 400 million oneyanaires. \n",
      "########## PREDICTED SENTIMENT: Positive ##########\n",
      "--------------------\n",
      "Parent ID: 7ck1f6\n",
      "Comment ID: dpqv9ll\n",
      "Hey, if these guys think they deserve to pay more in taxes, there's an area on any tax form that allows you to pay more. Just what you think you should pay in. Otherwise, you're just virtue signaling and/or demanding that **other people** pay more in taxes.\n",
      "########## PREDICTED SENTIMENT: Positive ##########\n",
      "--------------------\n",
      "Parent ID: 7ck1f6\n",
      "Comment ID: dpquexa\n",
      "There are 11 million millionaires in the U.S. \n",
      "\n",
      "You round up 400 and think that's a relevant statement for 'anything at all'? I swear, these headlines get more ignorant by the day.\n",
      "########## PREDICTED SENTIMENT: Positive ##########\n",
      "--------------------\n",
      "Parent ID: 7ck1f6\n",
      "Comment ID: dpqundt\n",
      "Pfff... Millionaires are practically middle class, if $400k/yr is... They *need* this tax break, don't you know...\n",
      "########## PREDICTED SENTIMENT: Positive ##########\n",
      "--------------------\n",
      "Parent ID: 7ck1f6\n",
      "Comment ID: dpqqzgz\n",
      "They are free to give their money away themselves. Bill Gates even shows that as individuals, they could spend that money more efficiently than the government.\n",
      "########## PREDICTED SENTIMENT: Positive ##########\n",
      "--------------------\n",
      "Parent ID: 7ck1f6\n",
      "Comment ID: dpqj9my\n",
      "Meanwhile Trump only wants to persecute [hedge fund managers](https://youtu.be/imaHj1jicEM)\n",
      "########## PREDICTED SENTIMENT: Neutral ##########\n",
      "--------------------\n",
      "Parent ID: 7ck1f6\n",
      "Comment ID: dpqtkxr\n",
      "Sorry guys, nice try but they don't listen to any of us either.\n",
      "########## PREDICTED SENTIMENT: Positive ##########\n",
      "--------------------\n",
      "Parent ID: 7ck1f6\n",
      "Comment ID: dpqu194\n",
      "As if the GOP gave a shit about the middle class. \n",
      "########## PREDICTED SENTIMENT: Positive ##########\n",
      "--------------------\n",
      "Parent ID: 7ck1f6\n",
      "Comment ID: dpqu24i\n",
      "Who cares about millionaires, what are the billionaires doing \n",
      "########## PREDICTED SENTIMENT: Positive ##########\n",
      "--------------------\n",
      "Parent ID: 7ck1f6\n",
      "Comment ID: dpquiru\n",
      "Oh please, somebody protect our millionaires!\n",
      "########## PREDICTED SENTIMENT: Positive ##########\n",
      "--------------------\n",
      "Parent ID: 7ck1f6\n",
      "Comment ID: dpqupql\n",
      "Cue the dumbasses on the right saying \"if u wanna pay moar then write a check!!1!\".\n",
      "########## PREDICTED SENTIMENT: Positive ##########\n",
      "--------------------\n",
      "Parent ID: 7ck1f6\n",
      "Comment ID: dpqurnj\n",
      "Congress will double down and give them even bigger breaks! Take that, fairness and equity!!!! \n",
      "########## PREDICTED SENTIMENT: Positive ##########\n",
      "--------------------\n",
      "Parent ID: 7ck1f6\n",
      "Comment ID: dpqut3i\n",
      "Sure, but did they TELL Congress with their wallets?  $ or GTFO\n",
      "########## PREDICTED SENTIMENT: Positive ##########\n",
      "--------------------\n",
      "Parent ID: 7ck1f6\n",
      "Comment ID: dpquvxd\n",
      "Just millionaires? To the people who are lining the GOP's pockets, millionaires are basically homeless people.\n",
      "########## PREDICTED SENTIMENT: Positive ##########\n",
      "--------------------\n",
      "Parent ID: 7ck1f6\n",
      "Comment ID: dpqv0lo\n",
      "but the 500 millonares in congress say do\n",
      "########## PREDICTED SENTIMENT: Positive ##########\n",
      "--------------------\n",
      "Parent ID: 7ck1f6\n",
      "Comment ID: dpqv88a\n",
      "Patriotic Millionaires is another group, as well.\n",
      "########## PREDICTED SENTIMENT: Positive ##########\n",
      "--------------------\n",
      "Parent ID: 7ck1f6\n",
      "Comment ID: dpqvajz\n",
      "Trump is a dumbshit\n",
      "\n",
      "########## PREDICTED SENTIMENT: Positive ##########\n",
      "--------------------\n",
      "Parent ID: 7ck1f6\n",
      "Comment ID: dpqveik\n",
      "\"Don't cut out taxes!!! Seriously... these people are all like... *super* pissed at us right now. This just isn't a good time... they're gonna rip us apart if you keep giving us more money!\"\n",
      "########## PREDICTED SENTIMENT: Positive ##########\n",
      "--------------------\n",
      "Parent ID: 7ck1f6\n",
      "Comment ID: dpqvkek\n",
      "these 400 (out of how many) millionaires are probably a minority. Those that have not spoken will also be the first to bitch and scream when roads, bridges and other vital infrastructure begins to crap out.... [edited for clarity purposes]\n",
      "########## PREDICTED SENTIMENT: Positive ##########\n",
      "--------------------\n",
      "Parent ID: 7ck1f6\n",
      "Comment ID: dpqvlsu\n",
      "Sorry dudes, your other millionaire/billionare brethren are greedier and far more insistent\n",
      "########## PREDICTED SENTIMENT: Positive ##########\n",
      "--------------------\n",
      "Parent ID: 7ck1f6\n",
      "Comment ID: dpqvm7v\n",
      "There are more than 10 million millionaires in the US:\n",
      "https://www.cnbc.com/2017/03/24/a-record-number-of-americans-are-now-millionaires-new-study-shows.html\n",
      "########## PREDICTED SENTIMENT: Positive ##########\n",
      "--------------------\n",
      "Parent ID: 7ck1f6\n",
      "Comment ID: dpqvs4n\n",
      "These 400 should start their own lobby. Only way to reach.  \n",
      "########## PREDICTED SENTIMENT: Positive ##########\n",
      "--------------------\n",
      "Parent ID: 7ck1f6\n",
      "Comment ID: dpqvsic\n",
      "We should sign a petition. \n",
      "########## PREDICTED SENTIMENT: Neutral ##########\n",
      "--------------------\n",
      "Parent ID: 7ck1f6\n",
      "Comment ID: dpqvyjq\n",
      "Billions world wide tell millionaires+ to stop hoarding resources to the detriment of the population of the planet. \n",
      "########## PREDICTED SENTIMENT: Positive ##########\n",
      "--------------------\n",
      "Parent ID: 7ck1f6\n",
      "Comment ID: dpqw0h2\n",
      "Won't matter unless they actually start paying them.\n",
      "########## PREDICTED SENTIMENT: Neutral ##########\n",
      "--------------------\n",
      "Parent ID: 7ck1f6\n",
      "Comment ID: dpqwf2n\n",
      "My professor always told us how the oil companies would work with the IRS to pay their fair share of taxes. Their fair share was a hugely discounted amount because of the deductions and credits they were allowed to take: about 15% effective rate. This sure beats modern giants which have their headquarters abroad to avoid their due.\n",
      "########## PREDICTED SENTIMENT: Positive ##########\n",
      "--------------------\n",
      "Parent ID: 7ck1f6\n",
      "Comment ID: dpqwju1\n",
      "Theyre afraid of the public backlash.\n",
      "########## PREDICTED SENTIMENT: Positive ##########\n",
      "--------------------\n",
      "Parent ID: 7ck1f6\n",
      "Comment ID: dpqwk0w\n",
      "Allowing wealth to be concentrated in a small portion of the whole population is a breach of the obligation of a State to reduce poverty with compliance of respecting human rights. \n",
      "########## PREDICTED SENTIMENT: Positive ##########\n",
      "--------------------\n",
      "Parent ID: 7ck1f6\n",
      "Comment ID: dpqmiqx\n",
      "Guess who aren't republican donators, and therefore matter naught. \n",
      "########## PREDICTED SENTIMENT: Positive ##########\n",
      "--------------------\n",
      "Parent ID: 7ck1f6\n",
      "Comment ID: dpqukd0\n",
      "Are they going to be somehow rendered incapable of using this money for charity if their taxes are not cut? \n",
      "########## PREDICTED SENTIMENT: Positive ##########\n",
      "--------------------\n",
      "Parent ID: 7ck1f6\n",
      "Comment ID: dpqv58g\n",
      "So 400 of the 11 million millionaires. \n",
      "########## PREDICTED SENTIMENT: Positive ##########\n",
      "--------------------\n",
      "Parent ID: 7ck1f6\n",
      "Comment ID: dpqv0hl\n",
      "Why not just create an option so people can donate money to the government directly? That way these millionaires can pay more as they wish, and everybody else gets to keep their money as they wish. Win-Win\n",
      "########## PREDICTED SENTIMENT: Positive ##########\n",
      "--------------------\n",
      "Parent ID: 7ck1f6\n",
      "Comment ID: dpqo2z5\n",
      "[deleted]\n",
      "########## PREDICTED SENTIMENT: Positive ##########\n",
      "--------------------\n",
      "Parent ID: 7ck1f6\n",
      "Comment ID: dpqj35u\n",
      "400 Millionaires vs. the rest of the mid.income and low income. Where is justice?\n",
      "########## PREDICTED SENTIMENT: Positive ##########\n",
      "--------------------\n",
      "Parent ID: 7ck1f6\n",
      "Comment ID: dpqjlhz\n",
      "I’ve yet to see one of these journalists get the top rate correct — it’s 43.4% currently with the 3.8% Obamacare surcharge. \n",
      "########## PREDICTED SENTIMENT: Positive ##########\n",
      "--------------------\n",
      "Parent ID: 7ck1f6\n",
      "Comment ID: dpqpna6\n",
      "They know the torches and pitchforks are coming and don't want to end up Guillotined.\n",
      "########## PREDICTED SENTIMENT: Positive ##########\n",
      "--------------------\n",
      "Parent ID: 7ck1f6\n",
      "Comment ID: dpqvf8f\n",
      "No one is stopping them from donating. What an idiotic thing to say. \n",
      "########## PREDICTED SENTIMENT: Positive ##########\n",
      "--------------------\n",
      "Parent ID: 7ck1f6\n",
      "Comment ID: dpqw3w5\n",
      "To answer the conservative dullards of Fox news / Moscow: \n",
      "\n",
      "First, \"only 400 out of the entire population\" argument is dumb because what petition do we ever have that is a significant portion of the population? These are the same people who call global warming or vaccines a \"theory\" because only 1 of scientist disagrees! \n",
      "\n",
      "Second, \"they can volunteer to pay more\" is not the point. They are arguing that Trickle down doesn't work, and they should know since they are not hiring anyone based on tax cuts and they are stating the problem is systemic. Our infrastructure is failing and our debt is increasing, neither of these problems are solved by voluntary tax donations.\n",
      "########## PREDICTED SENTIMENT: Positive ##########\n",
      "--------------------\n",
      "Parent ID: 7ck1f6\n",
      "Comment ID: dpqw89k\n",
      "Too bad it's the billionaire calling the shots. \n",
      "########## PREDICTED SENTIMENT: Positive ##########\n",
      "--------------------\n",
      "Parent ID: 7ck1f6\n",
      "Comment ID: dpqwgtr\n",
      "Good. If they cut their taxes they will bring their business to other countries, and jobs will leave the US. It is unfortunate that this is occuring, but it the sad reality.\n",
      "########## PREDICTED SENTIMENT: Positive ##########\n",
      "--------------------\n",
      "Parent ID: 7ck1f6\n",
      "Comment ID: dpqjajj\n",
      "I'm pretty sure they retain the ability to cut a check to the IRS or equvilent that goes above their tax liability. That would be a true measure of their opinion on the taxes they pay, not this easy fake concern bullshit. I just want to pat less taxes as middle class. I don't really care how it happens at this point\n",
      "########## PREDICTED SENTIMENT: Positive ##########\n",
      "--------------------\n",
      "Parent ID: 7ck1f6\n",
      "Comment ID: dpqhxx5\n",
      "This is idiotic.  Every one of them could donate voluntarily to the US government if they really feel that way and aren't just virtue signaling.\n",
      "########## PREDICTED SENTIMENT: Positive ##########\n",
      "--------------------\n",
      "Parent ID: 7ck1f6\n",
      "Comment ID: dpqtg57\n",
      "If only there was this thing called donating, they could give their money away without the government taking it.\n",
      "########## PREDICTED SENTIMENT: Neutral ##########\n",
      "--------------------\n",
      "Parent ID: 7ck1f6\n",
      "Comment ID: dpqvle6\n",
      "Those 400 millionaires are welcome to keep paying the same high percent they are now-  let me guess they're all democrats.  Mark Zuckerberg, Oprah, Bezos, Gates, etc are more than welcome to pay 99.9% of their current wealth to the US govt right now in taxes-  not before they die, not to charity.  To the US govt right now!!\n",
      "########## PREDICTED SENTIMENT: Positive ##########\n",
      "--------------------\n",
      "Parent ID: 7ck1f6\n",
      "Comment ID: dpqraap\n",
      "Let's see if they'll cut a check to make up the difference...\n",
      "\n",
      "My instincts tell me they won't and they'll *begrudgingly* take their tax cut.\n",
      "########## PREDICTED SENTIMENT: Positive ##########\n",
      "--------------------\n",
      "Parent ID: 7ck1f6\n",
      "Comment ID: dpqmtve\n",
      "I'm 27 years old, make $90,000 a year. The tax cuts help me and I hope they pass it. I hope they cut taxes for billionaires and I hope they cut corporate taxes to near 0%. They can pay for it by cutting many, many social programs for lazy unemployed and uneducated people who don't deserve it. None of those bitter people burning American flags deserve a single penny from the government. I hope they keep all benefits for veterans, they deserve it. \n",
      "########## PREDICTED SENTIMENT: Positive ##########\n",
      "--------------------\n",
      "Parent ID: 7ck1f6\n",
      "Comment ID: dpqowv8\n",
      "They can send extra to the irs  if they want to. \n",
      "It's not illegal to pay more.\n",
      "########## PREDICTED SENTIMENT: Positive ##########\n",
      "--------------------\n",
      "Parent ID: 7ck1f6\n",
      "Comment ID: dpqr2ut\n",
      "They should try donating instead\n",
      "########## PREDICTED SENTIMENT: Positive ##########\n",
      "--------------------\n",
      "Parent ID: 7ck1f6\n",
      "Comment ID: dpqnahl\n",
      "Are there even 400 million aries in the US?? i mean come on\n",
      "########## PREDICTED SENTIMENT: Positive ##########\n",
      "--------------------\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'MoreComments' object has no attribute 'parent'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-27-a5fc106c36c2>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     18\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mcomment\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mcomments\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m             \u001b[0mprint\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m20\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0;34m'-'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 20\u001b[0;31m             \u001b[0mprint\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m'Parent ID:'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcomment\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparent\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     21\u001b[0m             \u001b[0mprint\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m'Comment ID:'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcomment\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mid\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m             \u001b[0mprint\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mcomment\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbody\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'MoreComments' object has no attribute 'parent'"
     ]
    }
   ],
   "source": [
    "import praw\n",
    "\n",
    "#this is a read-only instance\n",
    "reddit = praw.Reddit(user_agent='first_scrape (by /u/dswald)',\n",
    "                     client_id='TyAK1zSuAvQjmA', \n",
    "                     client_secret=\"uxHGsL0zNODbowN6umVnBWpqLAQ\")\n",
    "\n",
    "subreddit = reddit.subreddit('politics')\n",
    "hot_python = subreddit.hot(limit = 3) #need to view >2 to get past promoted posts\n",
    "\n",
    "for submission in hot_python:\n",
    "    if not submission.stickied: #top 2 are promoted posts, labeled as 'stickied'\n",
    "        print('Title: {}, ups: {}, downs: {}, Have we visited: {}'.format(submission.title,\n",
    "                                                                          submission.ups,\n",
    "                                                                          submission.downs,\n",
    "                                                                          submission.visited))\n",
    "        comments = submission.comments.list() #unstructured\n",
    "        for comment in comments:\n",
    "            print (20*'-')\n",
    "            print ('Parent ID:', comment.parent())\n",
    "            print ('Comment ID:', comment.id)\n",
    "            print (comment.body)\n",
    "            print(\"#\"*10,'PREDICTED SENTIMENT:', prediction(comment.body),\"#\"*10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It seems that everythng is positive or neutral.  Is this because of a unigram model or too specific training data or what?  This is food for thought.  Committing now."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
